{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317efb3a-f24b-4677-a79c-8667727077d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies and the parser module\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from xbrl_parser import XbrlParser\n",
    "\n",
    "# Set target universe\n",
    "target_companies = [\"ajinomoto\", \"mufg\", \"toyota\", \"honda\"]\n",
    "target_fys = [f\"FY{y}\" for y in range(2015, 2025)]\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "for target_company in target_companies:\n",
    "    for target_fy in target_fys:\n",
    "        \n",
    "        # Define input file\n",
    "        xbrl_zip_path = current_dir / \"input\" / \"XBRL\" / target_company / (target_company+\"_\"+target_fy+\".zip\")\n",
    "        \n",
    "        # Define output file\n",
    "        parsed_csv_path = current_dir / \"output\" / target_company / (target_company+\"_\"+target_fy+\"_parsed_xbrl.csv\")\n",
    "        parsed_csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Generate objects\n",
    "        parser = XbrlParser(xbrl_zip_path)\n",
    "        df_xbrl = parser.parse()\n",
    "        \n",
    "        # Save data\n",
    "        df_xbrl.to_csv(parsed_csv_path, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a2443-9ba9-4092-b169-1004d3c60803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies and the parser module\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from financial_analyzer import FinancialAnalyzer, load_mapping_with_override\n",
    "from slides_core import (\n",
    "    SlideConfig,\n",
    "    PowerPointGeneratorEngine,\n",
    "    SlideCover,\n",
    "    SlideDeck,\n",
    "    SlidePage,\n",
    ")\n",
    "\n",
    "def extract_page_columns(page_def: dict) -> list:\n",
    "    mapping = page_def.get(\"data_mapping\", {})\n",
    "    category = page_def.get(\"category\")\n",
    "    cols = []\n",
    "    if category == \"combo_bar_line_2axis\":\n",
    "        cols += [t[\"col\"] for t in mapping.get(\"bar_traces\", [])]\n",
    "        cols += [t[\"col\"] for t in mapping.get(\"line_traces\", [])]\n",
    "        cols.append(mapping.get(\"x_col\", \"period_label\"))\n",
    "    elif category == \"balance_sheet\":\n",
    "        for stack_key in (\"left_stack\", \"left_stack_for_bank\", \"left_stack_summary\", \"right_stack\", \"right_stack_for_bank\", \"right_stack_summary\"):\n",
    "            cols += [item[\"col\"] for item in mapping.get(stack_key, [])]\n",
    "        cols.append(mapping.get(\"total_assets_col\", \"Total Assets\"))\n",
    "    elif category == \"portfolio_timeseries\":\n",
    "        cols += [t[\"col\"] for t in mapping.get(\"series\", [])]\n",
    "        cols.append(mapping.get(\"x_col\", \"period_label\"))\n",
    "    return sorted({col for col in cols if col})\n",
    "\n",
    "for target_company in target_companies:\n",
    "    csv_dir = current_dir / \"output\" / target_company\n",
    "    csv_files = list(csv_dir.glob(\"*.csv\"))\n",
    "    dfs = []\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(csv_file.resolve())\n",
    "        dfs.append(df)\n",
    "    df_target = pd.concat(dfs)\n",
    "    standard = None\n",
    "    if \"Standard\" in df_target.columns and not df_target[\"Standard\"].dropna().empty:\n",
    "        standard = df_target[\"Standard\"].dropna().mode().iloc[0]\n",
    "    mapping = load_mapping_with_override(Path(\"custom_mapping.json\"), standard=standard, company_name=target_company)\n",
    "    analyzer = FinancialAnalyzer(df_target, mapping=mapping, standard=standard, company_name=target_company)\n",
    "\n",
    "    df_pl = analyzer.get_pl_data()\n",
    "    df_bs = analyzer.get_bs_data()\n",
    "    df_pl.to_csv(f\"DUMP_{target_company}_PL.csv\", index=None)\n",
    "    df_bs.to_csv(f\"DUMP_{target_company}_BS.csv\", index=None)\n",
    "\n",
    "    data_store, slides_structure = analyzer.build_slide_payload()\n",
    "\n",
    "    sample_text = {\n",
    "        \"PL\": [\n",
    "            {\"title\": \"Margin\", \"body\": \"Operating income trend mirrors revenue, with limited margin expansion.\"},\n",
    "            {\"title\": \"Scale\", \"body\": \"Latest FY shows revenue recovery while operating income stabilizes.\"},\n",
    "        ],\n",
    "        \"BS\": [\n",
    "            {\"title\": \"Leverage\", \"body\": \"Equity share improves, but liabilities remain concentrated.\"},\n",
    "            {\"title\": \"Liquidity\", \"body\": \"Cash and equivalents fluctuate with working-capital swings.\"},\n",
    "        ],\n",
    "        \"CF\": [\n",
    "            {\"title\": \"Cash Conversion\", \"body\": \"Operating cash flow tracks profit with periodic volatility.\"},\n",
    "            {\"title\": \"Funding Mix\", \"body\": \"Financing flows offset investment outflows in down years.\"},\n",
    "        ],\n",
    "        \"Portfolio\": [\n",
    "            {\"title\": \"Risk Mix\", \"body\": \"Equity exposure rises relative to debt; derivatives net stays modest.\"},\n",
    "            {\"title\": \"Volatility\", \"body\": \"Portfolio size expands in strong years and contracts in tightening cycles.\"},\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    pages = []\n",
    "    for slide_def in slides_structure:\n",
    "        page_def = dict(slide_def)\n",
    "        source_key = page_def.pop(\"data_source\", None)\n",
    "        if source_key:\n",
    "            page_def[\"data_frame\"] = data_store.get(source_key)\n",
    "        page_def[\"data_columns\"] = extract_page_columns(page_def)\n",
    "        text_blocks = sample_text.get(page_def.get(\"slide_title\", \"\"))\n",
    "        if text_blocks:\n",
    "            page_def[\"text_blocks\"] = text_blocks\n",
    "            page_def[\"proposal_section_title\"] = \"Key Findings\"\n",
    "        pages.append(SlidePage(**page_def))\n",
    "\n",
    "    selected_pages = pages\n",
    "\n",
    "    cover = SlideCover(\n",
    "        main_title=f\"{target_company} Financial Review\",\n",
    "        sub_title=\"Generated from XBRL\",\n",
    "        date=datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    )\n",
    "\n",
    "    deck = SlideDeck(cover=cover, pages=selected_pages)\n",
    "    engine = PowerPointGeneratorEngine(SlideConfig())\n",
    "    engine.generate(\n",
    "        deck=deck,\n",
    "        data_store=data_store,\n",
    "        filename_prefix=f\"{target_company}_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4017f0d-9fa4-4d5f-b825-75a3d9cc0ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac3d40c-b58a-47af-b87c-94994fffc379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695b915-1317-4a7d-b9cc-05303163eb0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
